<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=dark data-auto-appearance=true><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><meta name=theme-color><title>The first block &#183; Project Abundance</title><meta name=title content="The first block &#183; Project Abundance"><meta name=description content="Node and farmer implementation are wired together enough to start producing blocks"><meta name=keywords content="status-update,"><link rel=canonical href=https://abundance.build/blog/2025-11-24-the-first-block/><link type=text/css rel=stylesheet href=/css/main.bundle.min.fd951ea54edeca1b6b08c8bbf3c93c284de4c78daf63a71d8016939775734cf68700f1662ed31d870100c676cbe1f65d150635cf368b874c49fc75147bcb04a9.css integrity="sha512-/ZUepU7eyhtrCMi788k8KE3kx42vY6cdgBaTl3VzTPaHAPFmLtMdhwEAxnbL4fZdFQY1zzaLh0xJ/HUUe8sEqQ=="><script type=text/javascript src=/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj+e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script><script defer type=text/javascript id=script-bundle src=/js/main.bundle.min.e4b2d9aece2aa7a740c3ee7a0efc5acf56b204868ab0fb5bba9be32aed1cd0c9262979d98050759068d58144297f74b12ed05b5173cf2df2e6c097a066b984a8.js integrity="sha512-5LLZrs4qp6dAw+56Dvxaz1ayBIaKsPtbupvjKu0c0MkmKXnZgFB1kGjVgUQpf3SxLtBbUXPPLfLmwJegZrmEqA==" data-copy=Copy data-copied=Copied></script><script src=/lib/zoom/zoom.min.umd.a527109b68c082a70f3697716dd72a9d5aa8b545cf800cecbbc7399f2ca6f6e0ce3e431f2062b48bbfa47c9ea42822714060bef309be073f49b9c0e30d318d7b.js integrity="sha512-pScQm2jAgqcPNpdxbdcqnVqotUXPgAzsu8c5nyym9uDOPkMfIGK0i7+kfJ6kKCJxQGC+8wm+Bz9JucDjDTGNew=="></script><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><meta property="og:url" content="https://abundance.build/blog/2025-11-24-the-first-block/"><meta property="og:site_name" content="Project Abundance"><meta property="og:title" content="The first block"><meta property="og:description" content="Node and farmer implementation are wired together enough to start producing blocks"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="blog"><meta property="article:published_time" content="2025-11-24T00:00:00+00:00"><meta property="article:modified_time" content="2025-11-24T00:00:00+00:00"><meta property="article:tag" content="status-update"><meta name=twitter:card content="summary"><meta name=twitter:title content="The first block"><meta name=twitter:description content="Node and farmer implementation are wired together enough to start producing blocks"><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"Blog","name":"The first block","headline":"The first block","description":"Node and farmer implementation are wired together enough to start producing blocks","abstract":"\u003cp\u003eIt has been a month since the last update, and I finally have more exciting news to share here. I received feedback\npreviously that grinding on the same topic is not particularly interesting, so I decided to wait for something different\nto happen, and it finally did, we\u0026rsquo;ve got the first block on the beacon chain!\u003c\/p\u003e","inLanguage":"en","url":"https:\/\/abundance.build\/blog\/2025-11-24-the-first-block\/","author":{"@type":"Person","name":""},"copyrightYear":"2025","dateCreated":"2025-11-24T00:00:00\u002b00:00","datePublished":"2025-11-24T00:00:00\u002b00:00","dateModified":"2025-11-24T00:00:00\u002b00:00","keywords":["status-update"],"mainEntityOfPage":"true","wordCount":"2820"}]</script><script src=/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj+KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>
Skip to main content</a></div><div class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start gap-x-3 pt-[2px] pr-0 pb-[3px] pl-0"><div class="flex flex-1 items-center justify-between"><nav class="flex space-x-3"><a href=/ class="text-base font-medium text-gray-500 hover:text-gray-900">Project Abundance</a></nav><nav class="hidden md:flex items-center gap-x-5 md:ml-12 h-12"></nav><div class="flex md:hidden items-center gap-x-5 md:ml-12 h-12"><span></span></div></div><div class="-my-2 md:hidden"><div id=menu-button class=block></div></div></div><div class="relative flex flex-col grow"><main id=main-content class=grow><article><header id=single_header class="mt-5 max-w-prose"><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">The first block</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime=2025-11-24T00:00:00+00:00>24 November 2025</time><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">14 mins</span><span class="px-2 text-primary-500">&#183;</span>
<span class=mb-[2px]><a href=https://github.com/nazar-pc/abundance/tree/main/website/main/content/blog/2025/2025-11-24-the-first-block.md class="text-lg hover:text-primary-500" rel="noopener noreferrer" target=_blank title="Edit content"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg height="1em" viewBox="0 0 512 512"><path fill="currentColor" d="M441 58.9 453.1 71c9.4 9.4 9.4 24.6.0 33.9L424 134.1 377.9 88 407 58.9c9.4-9.4 24.6-9.4 33.9.0zM209.8 256.2 344 121.9 390.1 168 255.8 302.2c-2.9 2.9-6.5 5-10.4 6.1L186.9 325l16.7-58.5c1.1-3.9 3.2-7.5 6.1-10.4zM373.1 25 175.8 222.2c-8.7 8.7-15 19.4-18.3 31.1l-28.6 1e2c-2.4 8.4-.1 17.4 6.1 23.6s15.2 8.5 23.6 6.1l1e2-28.6c11.8-3.4 22.5-9.7 31.1-18.3L487 138.9c28.1-28.1 28.1-73.7.0-101.8L474.9 25C446.8-3.1 401.2-3.1 373.1 25zM88 64C39.4 64 0 103.4.0 152V424c0 48.6 39.4 88 88 88H360c48.6.0 88-39.4 88-88V312c0-13.3-10.7-24-24-24s-24 10.7-24 24V424c0 22.1-17.9 40-40 40H88c-22.1.0-40-17.9-40-40V152c0-22.1 17.9-40 40-40H2e2c13.3.0 24-10.7 24-24s-10.7-24-24-24H88z"/></svg></span></span></a></span></div><div class="flex flex-row flex-wrap items-center"><a class="relative mt-[0.5rem] mr-2" href=/tags/status-update/><span class="flex cursor-pointer"><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">status-update</span></span></a></div></div><div class="flex author"><div class=place-self-center><div class="text-2xl sm:text-lg"></div></div></div><div class="flex author author-extra mt-4"><img class="!mt-0 !mb-0 h-24 w-24 rounded-full ltr:mr-4 rtl:ml-4" width=96 height=96 src=/3d67cc976284fd62356e2edd8a8dfc49_2651210052118205119_hu_2fd6f6eca7f7083d.jpg><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Author</div><a href=https://abundance.build/authors/nazar-pc/ class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">Nazar Mokrynskyi</a><div class="text-2xl sm:text-lg"><div class="flex flex-wrap text-neutral-400 dark:text-neutral-500"><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://linkedin.com/in/nazarpc target=_blank aria-label=Linkedin rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://x.com/nazarpc target=_blank aria-label=X-Twitter rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg></span></span></a>
<a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://github.com/nazar-pc target=_blank aria-label=Github rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=mailto:nazar@mokrynskyi.com target=_blank aria-label=Email rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg></span></span></a></div></div></div></div><div class=mb-5></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="min-w-0 min-h-0 max-w-fit"><div class="article-content max-w-prose mb-20"><p>It has been a month since the last update, and I finally have more exciting news to share here. I received feedback
previously that grinding on the same topic is not particularly interesting, so I decided to wait for something different
to happen, and it finally did, we&rsquo;ve got the first block on the beacon chain!</p><h2 class="relative group">Dependencies<div id=dependencies class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100 select-none"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700 !no-underline" href=#dependencies aria-label=Anchor>#</a></span></h2><p>It has been a relatively long process to figure out all the data structures and components before the node can be put
together and a farmer can connect to it. On the node side, both block production and import pipelines need to exist, as
well as RPC server for a farmer to connect to.</p><p>Basic block data structures and consensus pieces (although subtly broken) were in place for some time already. The
bigger problem was farmer, which both depended on Subspace networking stack and CUDA/ROCm-based GPU plotting. That
GPU-based plotting is what I spent the bulk of my time on last month.</p><h2 class="relative group">GPU plotting performance<div id=gpu-plotting-performance class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100 select-none"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700 !no-underline" href=#gpu-plotting-performance aria-label=Anchor>#</a></span></h2><p>While I shared that things worked during the last update, performance was not great. I&rsquo;m happy to report that with Mesa
RADV I was finally able to capture some profiling traces and figure out some bottlenecks. Now the performance matches
the CUDA/ROCm version in Subspace with lower VRAM and shared memory usage and support for a wide range of GPUs.</p><p>The biggest one turned out to be vector register pressure with almost all shaders and looked something like this:</p><p align=center><img alt="Radeon GPU Profiler screenshot before optimizations" src=rgp-before.png></p><p>As you can see, the shader which generates the second table used 96 vector registers on AMD RX 7600 XT GPU, and that was
limiting GPU occupancy to 5/16 available wavefronts. While not always a problem, it definitely was in this particular
case.</p><p>After tinkering with algorithms and rewriting the shaders I ended up with a profile that looks substantially different:</p><p align=center><img alt="Radeon GPU Profiler screenshot before optimizations" src=rgp-after.png></p><p>As you can see, both relative time improved and shaders are no longer limited by vector registers pressure. There are
likely other constraints still present, but I am not advanced enough in GPU programming to deal with that yet, and
performance is satisfactory as is.</p><p>Let me briefly share some optimizations I have done to achieve that.</p><h2 class="relative group">Rmap<div id=rmap class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100 select-none"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700 !no-underline" href=#rmap aria-label=Anchor>#</a></span></h2><p><code>Rmap</code>, as a reminder, is the data structure that allows to quickly find matches into the right table. It was a source
of optimizations before, and turned out not the last time. The major problems with it were that it was constructed
sequentially and was large, but frequently used data structure. The sequential nature was caused by the fact that there
are duplicated <code>Y</code> values in tables, and exactly first two should be used in the sorted order.</p><p>I tried solving the sequential nature of its of it in a few different ways. Each attempt was more successful than the
next, but also substantially different, and the ultimate solution is unlike anything before it. And I&rsquo;m skipping
complete, functional, but ultimately not fruitful results, which I had a few of.</p><p>The first attempt was in <a href=https://github.com/nazar-pc/abundance/pull/430 target=_blank>PR 430</a>, which added additional sorting steps before matching tables, such that it is
relatively easy to handle duplicates with subgroup operations. Then a piece of additional information is attached to
each <code>R</code> value, such that <code>Rmap</code> construction can be reduced to a bunch of concurrent atomic &ldquo;or&rdquo; operations. I used <code>R</code>
instead of <code>Y</code> since we know what bucket the value belongs to and with <code>R</code> value being in the range of <code>0..15113</code> there
were unused bits to store extra information &ldquo;for free&rdquo; (in terms of memory usage).</p><p>This worked better than the sequential version, but there were two additional sorts involved, which takes time, and the
preparation overall was still sequential, even though threads within subgroup cooperated to share values with each
other.</p><p>I then looked into parallel preparation. In <a href=https://github.com/nazar-pc/abundance/pull/431 target=_blank>PR 431</a> I parallelized the preparation step, such that all threads are
doing something useful at every step. I had a few more variations of this approach before and after, but they were not
better than this one.</p><p>This worked slightly better, but the complexity of the preparation step was quite high. Not to mention dreaded register
pressure. And something I kind of accepted at that point was that <code>Rmap</code> was still too large to fit into shared memory
on small iGPUs like one found on Raspberry PI 5, so it had to use global memory there. I don&rsquo;t think it&rsquo;d be too fast
there. So overall I was still unhappy with the result and was looking for alternatives.</p><p>And I did implement a drastically different alternative in <a href=https://github.com/nazar-pc/abundance/pull/435 target=_blank>PR 435</a>. I removed extra sorting steps and stopped storing
positions of <code>R</code>/<code>Y</code> values in <code>Rmap</code>. Instead, for each <code>R</code> I only reserve two bits, which indicate whether there was a
value present and if so, whether there was a second duplicate found or not. This is the kind of information that can be
efficiently constructed fully in parallel using atomic operations. This is then used to find matches. And only when
doing <code>compute_fn</code> step for the matches that were found, a full scan of the right bucket is performed to find the actual
position of <code>R</code> value we&rsquo;re dealing with.</p><p>This feels quite brilliant to me, and I&rsquo;m wondering why it took me so long to arrive with this simple and elegant
design. Not only it is much simpler, the fact that match doesn&rsquo;t store position of <code>R</code> values allowed me to smash all
the necessary information about the match into a single <code>u32</code> value: 9 bits for offset of the left value within a
bucket, 6 bits for <code>m</code> value, 14 bits for <code>R</code> target into the right table, and 1 bit to indicate whether the first or
second duplicate was used. The offset in the left table was not needed strictly speaking, but having it allowed to
further parallelize search for matches with quick sorting of matches afterward (initially implemented in [PR 433]).</p><p>With that my fighting with <code>Rmap</code> was over (at least for now) and it became so small (2 bits per <code>R</code> value instead of
9), it now fits nicely on smallest iGPUs in shared memory too!</p><h2 class="relative group">Sorting<div id=sorting class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100 select-none"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700 !no-underline" href=#sorting aria-label=Anchor>#</a></span></h2><p>The bitonic sorting I originally implemented within subgroup registers seemed really nice and elegant at first, I
thought it&rsquo;d perform really well, but nope! Turns out it was using way too many registers, especially on GPUs with
smaller subgroup sizes. Modern AMD GPUs have a subgroup size of 64, but Nvidia and many other GPUs have 32, which
doubles the number of registers needed to store the whole bucket.</p><p>Equipped with Radeon GPU Profiler I was finally able to see that. In <a href=https://github.com/nazar-pc/abundance/pull/433 target=_blank>PR 432</a> I refactored storting to not only sort
the values within shared memory, but also to make the whole workgroup sort the values, rather than subgroups, which made
the problem &ldquo;wider,&rdquo; and GPUs liked that. The algorithm became much more compact and easy to reason about too. This is
not the first time clever GPU code ended up being slower.</p><h2 class="relative group">Reducing memory and register usage<div id=reducing-memory-and-register-usage class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100 select-none"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700 !no-underline" href=#reducing-memory-and-register-usage aria-label=Anchor>#</a></span></h2><p>A pattern that I became annoyingly familiar with on GPUs is that the memory is scarce (fast memory, like vector
registers and shared memory) and I ended up smashing multiple values into the same <code>u32</code> over and over again. For
example, for example, in [PR 433] I was able to combine position and bucket offset to reduce <code>Match</code> data
structure from 12 to 8 bytes, which was further reduced to 4 bytes in <a href=https://github.com/nazar-pc/abundance/pull/435 target=_blank>PR 435</a> by storing 4 separate values in one
<code>u32</code>. The ALU cost to extract those values paid off every single time!</p><p>Noticing that trend, I looked at some of the larger types and noticed metadata. On CPU <code>u128</code> Rust type is used for
metadata, which works nicely, but this type is not supported on GPUs. I had to implement polyfills with <code>u32</code> and <code>u64</code>
to get something that resembles <code>u128</code>, but turned out I didn&rsquo;t need all 128 bits, at least not yet. Moreover, <code>u64</code>
while is supported by modern GPUs, it required compiling two versions of each shader and after experiments was also
using more vector registers than polyfills that use <code>u32</code>.</p><p>With that knowledge, I removed the second version of the shader in <a href=https://github.com/nazar-pc/abundance/pull/436 target=_blank>PR 436</a>, implemented generic <code>U32N</code> polyfll instead
of <code>U128</code> in <a href=https://github.com/nazar-pc/abundance/pull/438 target=_blank>PR 438</a> and finally switched to <code>U32N&lt;3></code> for metadata in <a href=https://github.com/nazar-pc/abundance/pull/439 target=_blank>PR 439</a>, which both helped to reduce register
usage and reduced memory usage by metadata by 25%. Hypothetically, it is possible to take advantage of it even more
since some tables do not even need three words to store metadata. However, implementing that in a generic way was too
much for the current state of const generics in Rust and I abandoned the idea after a few failed attempts.</p><p>Probably one of the most confusing and counter-intuitive sources of register usage today with rust-gpu is loops. It is
extremely common to use the to process batches of elements, yet it causes so much trouble!</p><p>For example, originally the shaders were prepared for odd numbers of workgroups to be dispatched (both larger and
smaller than necessary). However, removing that in <a href=https://github.com/nazar-pc/abundance/pull/433 target=_blank>PR 432</a> from all shaders made a substantial improvement in register
usage, despite it being a single loop.</p><p>A more extreme example of the same was in <a href=https://github.com/nazar-pc/abundance/pull/440 target=_blank>PR 440</a>, where <code>find_proofs</code> shader was efficiently loading data from global
memory using 5 nested loops that each were doing exactly two iterations. Simply having those loops meant that to track
their progress, at least 5 <code>u32</code> registers were needed, despite only storing two bits of information in each. So I
smashed them all into a single <code>u32</code> with a sprinkle of bit shifts. It is not pretty but allowed to achieve full
occupancy and improve performance in that particular shader. I wish there was a more readable way to do it, though.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-diff data-lang=diff><span class=line><span class=cl><span class=gd>--- a/crates/farmer/ab-proof-of-space-gpu/src/shader/find_proofs.rs
</span></span></span><span class=line><span class=cl><span class=gd></span><span class=gi>+++ b/crates/farmer/ab-proof-of-space-gpu/src/shader/find_proofs.rs
</span></span></span><span class=line><span class=cl><span class=gi></span><span class=gu>@@ -280,12 +280,14 @@ fn find_proofs_impl&lt;const SUBGROUP_SIZE: u32&gt;(
</span></span></span><span class=line><span class=cl><span class=gu></span>
</span></span><span class=line><span class=cl>     let mut group_left_x_index = subgroup_local_invocation_id * 2;
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=gd>-    // TODO: This uses a lot of registers for all the loops and expressions, optimize it further
</span></span></span><span class=line><span class=cl><span class=gd></span><span class=gi>+    // `chunk_index` is used to emulate `for _ in 0..2` loops, while using a single variable for
</span></span></span><span class=line><span class=cl><span class=gi>+    // tracking the progress instead of a separate variable for each loop
</span></span></span><span class=line><span class=cl><span class=gi>+    let mut chunk_index = 0u32;
</span></span></span><span class=line><span class=cl><span class=gi></span>     // Reading positions from table 6
</span></span><span class=line><span class=cl><span class=gd>-    for table_6_chunk in 0..2 {
</span></span></span><span class=line><span class=cl><span class=gd></span><span class=gi>+    loop {
</span></span></span><span class=line><span class=cl><span class=gi></span>         let table_6_proof_targets = subgroup_shuffle(
</span></span><span class=line><span class=cl>             table_6_proof_targets,
</span></span><span class=line><span class=cl><span class=gd>-            SUBGROUP_SIZE / 2 * table_6_chunk + subgroup_local_invocation_id / 2,
</span></span></span><span class=line><span class=cl><span class=gd></span><span class=gi>+            SUBGROUP_SIZE / 2 * (chunk_index &amp; 1) + subgroup_local_invocation_id / 2,
</span></span></span><span class=line><span class=cl><span class=gi></span>         );
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=gu>@@ -297,10 +299,11 @@ fn find_proofs_impl&lt;const SUBGROUP_SIZE: u32&gt;(
</span></span></span><span class=line><span class=cl><span class=gu></span>
</span></span><span class=line><span class=cl>         // Reading positions from table 5
</span></span><span class=line><span class=cl><span class=gd>-        for table_5_chunk in 0..2 {
</span></span></span><span class=line><span class=cl><span class=gd></span><span class=gi>+        chunk_index &lt;&lt;= 1;
</span></span></span><span class=line><span class=cl><span class=gi>+        loop {
</span></span></span><span class=line><span class=cl><span class=gi></span>             let table_5_proof_targets = subgroup_shuffle(
</span></span><span class=line><span class=cl>                 table_5_proof_targets,
</span></span><span class=line><span class=cl><span class=gd>-                SUBGROUP_SIZE / 2 * table_5_chunk + subgroup_local_invocation_id / 2,
</span></span></span><span class=line><span class=cl><span class=gd></span><span class=gi>+                SUBGROUP_SIZE / 2 * (chunk_index &amp; 1) + subgroup_local_invocation_id / 2,
</span></span></span><span class=line><span class=cl><span class=gi></span>             );
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=gu>@@ -312,10 +315,11 @@ fn find_proofs_impl&lt;const SUBGROUP_SIZE: u32&gt;(
</span></span></span><span class=line><span class=cl><span class=gu></span>
</span></span><span class=line><span class=cl>             // Reading positions from table 4
</span></span><span class=line><span class=cl><span class=gd>-            for table_4_chunk in 0..2 {
</span></span></span><span class=line><span class=cl><span class=gd></span><span class=gi>+            chunk_index &lt;&lt;= 1;
</span></span></span><span class=line><span class=cl><span class=gi>+            loop {
</span></span></span><span class=line><span class=cl><span class=gi></span>                 let table_4_proof_targets = subgroup_shuffle(
</span></span><span class=line><span class=cl>                     table_4_proof_targets,
</span></span><span class=line><span class=cl><span class=gd>-                    SUBGROUP_SIZE / 2 * table_4_chunk + subgroup_local_invocation_id / 2,
</span></span></span><span class=line><span class=cl><span class=gd></span><span class=gi>+                    SUBGROUP_SIZE / 2 * (chunk_index &amp; 1) + subgroup_local_invocation_id / 2,
</span></span></span><span class=line><span class=cl><span class=gi></span>                 );
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=gu>@@ -327,10 +331,11 @@ fn find_proofs_impl&lt;const SUBGROUP_SIZE: u32&gt;(
</span></span></span><span class=line><span class=cl><span class=gu></span>
</span></span><span class=line><span class=cl>                 // Reading positions from table 3
</span></span><span class=line><span class=cl><span class=gd>-                for table_3_chunk in 0..2 {
</span></span></span><span class=line><span class=cl><span class=gd></span><span class=gi>+                chunk_index &lt;&lt;= 1;
</span></span></span><span class=line><span class=cl><span class=gi>+                loop {
</span></span></span><span class=line><span class=cl><span class=gi></span>                     let table_3_proof_targets = subgroup_shuffle(
</span></span><span class=line><span class=cl>                         table_3_proof_targets,
</span></span><span class=line><span class=cl><span class=gd>-                        SUBGROUP_SIZE / 2 * table_3_chunk + subgroup_local_invocation_id / 2,
</span></span></span><span class=line><span class=cl><span class=gd></span><span class=gi>+                        SUBGROUP_SIZE / 2 * (chunk_index &amp; 1) + subgroup_local_invocation_id / 2,
</span></span></span><span class=line><span class=cl><span class=gi></span>                     );
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=gu>@@ -342,10 +347,12 @@ fn find_proofs_impl&lt;const SUBGROUP_SIZE: u32&gt;(
</span></span></span><span class=line><span class=cl><span class=gu></span>
</span></span><span class=line><span class=cl>                     // Reading positions from table 2
</span></span><span class=line><span class=cl><span class=gd>-                    for table_2_chunk in 0..2 {
</span></span></span><span class=line><span class=cl><span class=gd></span><span class=gi>+                    chunk_index &lt;&lt;= 1;
</span></span></span><span class=line><span class=cl><span class=gi>+                    loop {
</span></span></span><span class=line><span class=cl><span class=gi></span>                         let table_2_proof_targets = subgroup_shuffle(
</span></span><span class=line><span class=cl>                             table_2_proof_targets,
</span></span><span class=line><span class=cl><span class=gd>-                            SUBGROUP_SIZE / 2 * table_2_chunk + subgroup_local_invocation_id / 2,
</span></span></span><span class=line><span class=cl><span class=gd></span><span class=gi>+                            SUBGROUP_SIZE / 2 * (chunk_index &amp; 1)
</span></span></span><span class=line><span class=cl><span class=gi>+                                + subgroup_local_invocation_id / 2,
</span></span></span><span class=line><span class=cl><span class=gi></span>                         );
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=gu>@@ -439,10 +446,39 @@ fn find_proofs_impl&lt;const SUBGROUP_SIZE: u32&gt;(
</span></span></span><span class=line><span class=cl><span class=gu></span>                                 );
</span></span><span class=line><span class=cl>                             }
</span></span><span class=line><span class=cl>                         }
</span></span><span class=line><span class=cl><span class=gi>+
</span></span></span><span class=line><span class=cl><span class=gi>+                        if chunk_index &amp; 1 == 1 {
</span></span></span><span class=line><span class=cl><span class=gi>+                            break;
</span></span></span><span class=line><span class=cl><span class=gi>+                        }
</span></span></span><span class=line><span class=cl><span class=gi>+                        chunk_index += 1;
</span></span></span><span class=line><span class=cl><span class=gi>+                    }
</span></span></span><span class=line><span class=cl><span class=gi>+                    chunk_index &gt;&gt;= 1;
</span></span></span><span class=line><span class=cl><span class=gi>+
</span></span></span><span class=line><span class=cl><span class=gi>+                    if chunk_index &amp; 1 == 1 {
</span></span></span><span class=line><span class=cl><span class=gi>+                        break;
</span></span></span><span class=line><span class=cl><span class=gi></span>                     }
</span></span><span class=line><span class=cl><span class=gi>+                    chunk_index += 1;
</span></span></span><span class=line><span class=cl><span class=gi>+                }
</span></span></span><span class=line><span class=cl><span class=gi>+                chunk_index &gt;&gt;= 1;
</span></span></span><span class=line><span class=cl><span class=gi>+
</span></span></span><span class=line><span class=cl><span class=gi>+                if chunk_index &amp; 1 == 1 {
</span></span></span><span class=line><span class=cl><span class=gi>+                    break;
</span></span></span><span class=line><span class=cl><span class=gi></span>                 }
</span></span><span class=line><span class=cl><span class=gi>+                chunk_index += 1;
</span></span></span><span class=line><span class=cl><span class=gi></span>             }
</span></span><span class=line><span class=cl><span class=gi>+            chunk_index &gt;&gt;= 1;
</span></span></span><span class=line><span class=cl><span class=gi>+
</span></span></span><span class=line><span class=cl><span class=gi>+            if chunk_index &amp; 1 == 1 {
</span></span></span><span class=line><span class=cl><span class=gi>+                break;
</span></span></span><span class=line><span class=cl><span class=gi>+            }
</span></span></span><span class=line><span class=cl><span class=gi>+            chunk_index += 1;
</span></span></span><span class=line><span class=cl><span class=gi>+        }
</span></span></span><span class=line><span class=cl><span class=gi>+        chunk_index &gt;&gt;= 1;
</span></span></span><span class=line><span class=cl><span class=gi>+
</span></span></span><span class=line><span class=cl><span class=gi>+        if chunk_index &amp; 1 == 1 {
</span></span></span><span class=line><span class=cl><span class=gi>+            break;
</span></span></span><span class=line><span class=cl><span class=gi></span>         }
</span></span><span class=line><span class=cl><span class=gi>+        chunk_index += 1;
</span></span></span><span class=line><span class=cl><span class=gi></span>     }
</span></span><span class=line><span class=cl> }
</span></span></code></pre></div><h2 class="relative group">Concurrent GPU plotting<div id=concurrent-gpu-plotting class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100 select-none"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700 !no-underline" href=#concurrent-gpu-plotting aria-label=Anchor>#</a></span></h2><p>One thing I disliked a lot about Subspace&rsquo;s CUDA/ROCm implementation is that it was using <a href=https://github.com/supranational/sppark target=_blank>sppark</a> that is written with
some bad (IMO) architectural decisions. Not only, it doesn&rsquo;t allow to this day to support CUDA and ROCm in the same
process (either CUDA or ROCm needs to be selected at compile time, but not both), it uses global singletons for &ldquo;GPUs.&rdquo;
What that means is that it is not possible to instantiate the same GPU multiple times and make it run multiple
independent computations concurrently. However, as we discovered experimentally over the years, that is very beneficial
for performance. So users had to run multiple instances of the farmer even with a single GPU just to utilize it fully.</p><p>Not being tied to that library and relying on Vulkan instead, make it quite straightforward to implement. In <a href=https://github.com/nazar-pc/abundance/pull/441 target=_blank>PR 441</a> I
implemented support for multiple concurrent record encodings on the same GPU with the default being 4 for dGPU and 2 for
iGPU (seems about right from my experiments). The only complication is that <code>wgpu</code>&rsquo;s APIs currently do not support
multiple dispatch queues per GPU, so I had to instantiate multiple &ldquo;devices&rdquo; instead, which is probably slightly less
optimal than it would be otherwise, but it works. Finally, no need to open multiple farmers, everything &ldquo;just works&rdquo; out
of the box, like it does with CPU plotting and NUMA support there.</p><h2 class="relative group">Moving farmer and first block production<div id=moving-farmer-and-first-block-production class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100 select-none"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700 !no-underline" href=#moving-farmer-and-first-block-production aria-label=Anchor>#</a></span></h2><p>Now that GPU plotting is no longer a blocker, I did some preparation by moving crates in <a href=https://github.com/nazar-pc/abundance/pull/437 target=_blank>PR 437</a> and <a href=https://github.com/nazar-pc/abundance/pull/444 target=_blank>PR 444</a> (mostly
networking stack and some primitives). Then in <a href=https://github.com/nazar-pc/abundance/pull/445 target=_blank>PR 445</a> <code>ab-farmer</code> was finally created from <code>subspace-farmer</code>.</p><p>Having a farmer is nice, but the node was not complete, the biggest missing piece on the surface was the lack of RPC
server to connect to. I added one in <a href=https://github.com/nazar-pc/abundance/pull/448 target=_blank>PR 448</a> alongside a bunch of fixes (some of which were extracted into <a href=https://github.com/nazar-pc/abundance/pull/446 target=_blank>PR 446</a>)
and previously lacking consensus archiving implementation.</p><p>With that, the first blocks were produced:</p><pre tabindex=0><code>2025-11-23T19:49:38.853648Z  INFO ab_node::cli::run: ‚úåÔ∏è Abundance 0.0.1
2025-11-23T19:49:38.853674Z  INFO ab_node::cli::run: üìã Chain specification: dev
2025-11-23T19:49:38.853680Z  INFO ab_node::cli::run: üíæ Database path: /tmp/ab-node-HctAVm
2025-11-23T19:49:38.853961Z  INFO ab_node::cli::run: Started farmer RPC server address=127.0.0.1:9944
2025-11-23T19:49:38.853978Z  INFO ab_client_archiving::archiving: Not creating object mappings
2025-11-23T19:49:38.853989Z  INFO ab_client_archiving::archiving: Starting archiving from genesis
2025-11-23T19:49:38.853995Z  INFO ab_client_archiving::archiving: Archiving already produced blocks 0..=0
2025-11-23T19:50:31.609669Z  INFO ab_client_block_authoring::slot_worker: üîñ Built new block slot=27 number=1 root=d5217acac57cf25f598630b87ad9b4c4bfdc9b3f41c5d51badf1fed3a052375f pre_seal_hash=ad3d9fbddcbb178ace0f2f3d1a0d1b23dc54deeea726d9cae29e82a20025ee18
2025-11-23T19:50:31.613833Z  INFO ab_client_block_import::beacon_chain: üèÜ Imported block number=1 root=d5217acac57cf25f598630b87ad9b4c4bfdc9b3f41c5d51badf1fed3a052375f
2025-11-23T19:50:46.991342Z  INFO ab_client_block_authoring::slot_worker: üîñ Built new block slot=36 number=2 root=37e75ce4794c99d6ede6ae1dbc14fb3ce3fbeaff144b3a2971c6cffb80771d74 pre_seal_hash=f492d7264ca3b05aae49f1a88107b48c6bd9c1ff6ee6a352add7bbd9758fa6fc
2025-11-23T19:50:46.994170Z  INFO ab_client_block_import::beacon_chain: üèÜ Imported block number=2 root=37e75ce4794c99d6ede6ae1dbc14fb3ce3fbeaff144b3a2971c6cffb80771d74
2025-11-23T19:50:50.425401Z  INFO ab_client_block_authoring::slot_worker: üîñ Built new block slot=38 number=3 root=5dbbbf2468e60e52edf57ddbe4ced4cefe35b1754cafdc139abba1edd86de973 pre_seal_hash=099d9d2e79bf854d720181482317bbf44920c43ce9e63303128b4b64a16c2a22
2025-11-23T19:50:50.428264Z  INFO ab_client_block_import::beacon_chain: üèÜ Imported block number=3 root=5dbbbf2468e60e52edf57ddbe4ced4cefe35b1754cafdc139abba1edd86de973
2025-11-23T19:50:52.120060Z  INFO ab_client_block_authoring::slot_worker: üîñ Built new block slot=39 number=4 root=a3b7e8fa84a33996e80c57bfeff7c9cf4187203f488a6534a611a8ce0ec23d0d pre_seal_hash=f21c74285fa56ffb1c18b5d90e08e87be929bb590107c61cafbce80b5ab32571
2025-11-23T19:50:52.122686Z  INFO ab_client_block_import::beacon_chain: üèÜ Imported block number=4 root=a3b7e8fa84a33996e80c57bfeff7c9cf4187203f488a6534a611a8ce0ec23d0d
</code></pre><p>There is a lot of work ahead now, but having something like this working is an important milestone nevertheless.</p><p>This is a blockchain node built from scratch, no Substrate or anything like that.</p><h2 class="relative group">Upcoming plans<div id=upcoming-plans class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100 select-none"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700 !no-underline" href=#upcoming-plans aria-label=Anchor>#</a></span></h2><p>I am aware of some mismatch between GPU and CPU plotter, so I&rsquo;ll have to look into that soonish (GPU is used
automatically, so I&rsquo;m now testing it all the time by simply starting a farmer).</p><p>I&rsquo;ll probably do some updates to the node and start tackling countless TODOs everywhere before considering adding
support for intermediate and leaf shards into the mix.</p><p>The major items will be working on the database again, there are too many TODOs there, and there are some architectural
changes needed to support different kinds of shards.</p><p>The networking stack is something I&rsquo;m not particularly happy with. I&rsquo;m not even 100% sure about going with libp2p
anymore, its APIs are quite cumbersome to use, and I have a persistent feeling that there must be a better way.</p><p>And I&rsquo;ve been doing occasional research about RISC-V interpreter/VM design. I have more answers for myself now, but
ideally, I&rsquo;m looking for someone with experience to work on this for not a lot of money, so if you know someone who
might be interested, please let me know.</p><p>With that, the post is long enough as is. I&rsquo;ll plan for more frequent updates again in the future, a month was the
longest gap between posts so far. In case you are curious about something sooner, <a href=https://abundance.zulipchat.com/ target=_blank>Zulip</a> is a good place to ping me.</p></div></div><script type=text/javascript src=/js/page.min.54b6f4371722649edbe871e431d8670d670878c22be8f36e229fe53cc9b786fe25a834def5e6de621f7a3e37b72bc8cd73839aa5ed907ed6cbd45cd3e1b0fa20.js integrity="sha512-VLb0NxciZJ7b6HHkMdhnDWcIeMIr6PNuIp/lPMm3hv4lqDTe9ebeYh96Pje3K8jNc4Oape2QftbL1FzT4bD6IA==" data-oid=views_blog/2025/2025-11-24-the-first-block.md data-oid-likes=likes_blog/2025/2025-11-24-the-first-block.md></script></section><footer class="pt-8 max-w-prose print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="flex group mr-3" href=/blog/2025-10-23-gpu-plotting-works/><span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&larr;</span>
<span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">GPU plotting works!</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2025-10-23T00:00:00+00:00>23 October 2025</time>
</span></span></a></span><span><a class="flex text-right group ml-3" href=/blog/2025-12-02-the-first-10k-blocks/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">The first 10k blocks</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2025-12-02T00:00:00+00:00>2 December 2025</time>
</span></span><span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&larr;</span></a></span></div></div></footer></article><div id=top-scroller class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0 z-10"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer id=site-footer class="py-10 print:hidden"><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400"><a href=https://creativecommons.org/publicdomain/zero/1.0/ target=_blank rel="license noopener noreferrer">CC0 1.0 Universal</a></p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://blowfish.page/ target=_blank rel="noopener noreferrer">Blowfish</a></p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script><script type=text/javascript src=/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh+sCQ0E53ghYrxgYqw+0GCRyIEpA=="></script></footer></div></body></html>